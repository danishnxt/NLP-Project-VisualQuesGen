{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (7,7) # Make the figures a bit bigger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.core import Dense, Dropout, Reshape\n",
    "from keras.layers import GRU, Input, Concatenate, RepeatVector, Embedding, Lambda, Conv2D, Conv2DTranspose, Conv1D\n",
    "from keras.layers import MaxPooling1D, Flatten, TimeDistributed, SeparableConv2D\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau, Callback\n",
    "from keras.applications import vgg16 as vgg16_model\n",
    "from keras import objectives\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9450\n",
      "13117\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '..\\Dataset\\\\'\n",
    "images_dir = 'C:\\MsData\\\\'\n",
    "\n",
    "model_name = 'ctcnet-' + str(datetime.now().date())\n",
    "# if not os.path.exists('./'+model_name):\n",
    "#     os.mkdir(model_name)\n",
    "\n",
    "np.random.seed(42) # change this back?\n",
    "\n",
    "with open(dataset_dir+'fcn_index2word.npy', 'rb') as f:\n",
    "    index2word = np.load(f)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "max_len = 20\n",
    "vocab_size = len(index2word)\n",
    "print(vocab_size)\n",
    "print(len(os.listdir(images_dir)))\n",
    "\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(sample):\n",
    "    im = cv2.cvtColor(cv2.imread(images_dir+sample['image_id']+'.jpg'), cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (input_shape[0], input_shape[1]))\n",
    "    im = im / 255.0\n",
    "\n",
    "    wOutput = np.zeros((max_len,vocab_size+1))\n",
    "    row_index = np.arange(0, max_len)\n",
    "    col_index = sample['question']\n",
    "    wOutput[row_index, col_index] = 1\n",
    "    \n",
    "    WLogits = np.array(sample['question'])\n",
    "    \n",
    "    dummy_out = np.zeros((1,))\n",
    "    \n",
    "    return im, wOutput, WLogits, dummy_out\n",
    "    \n",
    "def data_generator(df, batch_size):\n",
    "    indexes = np.arange(0, len(df), batch_size)\n",
    "    \n",
    "    # Last value removed to prevent creation of a batch with size < batch_size \n",
    "    # incase the dataset can not be divided into the correct number of batches\n",
    "    # given the predefined batch_size\n",
    "    # This approach effectively reduces the number of batches by 1\n",
    "    \n",
    "    if len(df) % batch_size != 0:\n",
    "        indexes = indexes[:-1] \n",
    "    \n",
    "    while True: # 1 iteration represents 1 epoch\n",
    "        np.random.shuffle(indexes) # indexes shuffled for each epoch\n",
    "        for index in indexes: # 1 iteration represents 1 batch\n",
    "            batch_examples = df.iloc[index : index+batch_size].reset_index()\n",
    "                        \n",
    "            Xim = np.zeros((32, *input_shape))\n",
    "            Xseq = np.zeros((32, max_len, vocab_size+1))\n",
    "            Xlogit = np.zeros((32, max_len))\n",
    "            Ys = np.zeros((32, 1))\n",
    "            for index, row in batch_examples.iterrows(): # 1 iteration represents 1 entry in a batch\n",
    "                \n",
    "                xim, xseq, xlogit, y = get_sample(row)\n",
    "                Xim[index, :, :, :] = xim\n",
    "                Xseq[index, :, :] = xseq\n",
    "                Xlogit[index, :] = xlogit\n",
    "                Ys[index, :] = y # ONE MODIFICATION MADE HERE \n",
    "\n",
    "            yield [Xim,Xseq,Xlogit], Ys\n",
    "\n",
    "###########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  (55614, 2)\n",
      "Training samples: 35592 Validation samples: 11123 Testing samples: 8899\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(dataset_dir+'fcn_data.csv').astype('object')\n",
    "dataset['question'] = dataset['question'].apply(lambda x: eval(x))\n",
    "print('Dataset size: ', dataset.shape)\n",
    "\n",
    "train_set, val_set = train_test_split(dataset, test_size=0.2,random_state = 42)\n",
    "train_set, test_set = train_test_split(train_set, test_size=0.2, random_state = 37)\n",
    "print('Training samples:', len(train_set), 'Validation samples:', len(val_set), 'Testing samples:', len(test_set))\n",
    "\n",
    "train_gen = data_generator(train_set, batch_size)\n",
    "val_gen = data_generator(val_set, batch_size)\n",
    "test_gen = data_generator(test_set, batch_size)\n",
    "\n",
    "vggWeight = '../Weights/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "vgg16 = vgg16_model.VGG16(include_top=True, weights=None, input_shape=input_shape, classes=1000)\n",
    "vgg16.load_weights(vggWeight)\n",
    "\n",
    "vgg16.layers.pop()\n",
    "vgg16.layers.pop()\n",
    "vgg16.layers.pop()\n",
    "vgg16.layers.pop()\n",
    "for l in vgg16.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "image_embedding_model = Model(vgg16.input, vgg16.layers[-1].output, name='VGG16')\n",
    "\n",
    "\n",
    "feature_transformer = Sequential([\n",
    "    Reshape((49,512)),\n",
    "    Conv1D(512, kernel_size=(3,), strides=(2,), activation='relu', padding='valid'),\n",
    "    Conv1D(512, kernel_size=(5,), strides=(1,), activation='relu', padding='valid'),\n",
    "#     Conv1D(vocab_size, kernel_size=(1,), strides=(1,), activation=None, padding='valid')\n",
    "    Dense(vocab_size+1, activation=None)\n",
    "], name='feature_transformer')\n",
    "\n",
    "\n",
    "# def feature_transformer(x):\n",
    "#     y = Reshape((49,512))(x)\n",
    "#     y = Conv1D(512, kernel_size=(3,), strides=(2,), activation='relu', padding='valid')(y)\n",
    "#     y = Conv1D(512, kernel_size=(5,), strides=(1,), activation='relu', padding='valid')(y)\n",
    "#     y = Dense(vocab_size, activation=None)(y)\n",
    "#     return y\n",
    "\n",
    "def transpose_image(i):\n",
    "    return K.permute_dimensions(i, (0,2,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image\n",
    "input_im = Input(shape=(input_shape), name='input_im') \n",
    "input_im_trans = Lambda(transpose_image, name='input_im_transpose')(input_im)\n",
    "\n",
    "# Branch 1\n",
    "image_features = image_embedding_model(input_im)\n",
    "out_seq = feature_transformer(image_features)\n",
    "\n",
    "# Branch 2 (Transpose)\n",
    "image_features_trans = image_embedding_model(input_im_trans)\n",
    "out_seq_trans = feature_transformer(image_features_trans)\n",
    "\n",
    "# vector of length 'batch_size' containing same value everywhere = 'max_len'\n",
    "\n",
    "\n",
    "def custom_loss(arg_list):\n",
    "\n",
    "    seq_lens = np.ones((batch_size,1))*max_len\n",
    "\n",
    "    y_true_val, label_logits, y_pred1, y_pred2 = arg_list\n",
    "    \n",
    "    y_pred_prob = K.softmax(y_pred1, axis=1)\n",
    "    cat_cross_ent = objectives.categorical_crossentropy(y_true_val, y_pred_prob)\n",
    "    \n",
    "    y_pred_trans_prob = K.softmax(y_pred2, axis=1)\n",
    "    cat_cross_ent_trans = objectives.categorical_crossentropy(y_true_val, y_pred_trans_prob)\n",
    "    \n",
    "    # PROB PRESENT IN THE TWO VARIABLES PRESENT BELOW\n",
    "\n",
    "    ctc_orig = K.ctc_batch_cost(y_true=label_logits, y_pred=y_pred1, \n",
    "                                input_length=seq_lens, label_length=seq_lens)\n",
    "    \n",
    "    ctc_trans = K.ctc_batch_cost(y_true=label_logits, y_pred=y_pred2, \n",
    "                                 input_length=seq_lens, label_length=seq_lens)\n",
    "\n",
    "    return cat_cross_ent + cat_cross_ent_trans# + ctc_orig + ctc_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_result(arg_list):\n",
    "    predA, predB = arg_list # get both ways in\n",
    "    \n",
    "    \n",
    "    A_pred_prob = K.softmax(predA, axis=1)\n",
    "    B_pred_prob = K.softmax(predB, axis=1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_seq = Input(shape=(max_len,vocab_size+1), name='label_seq') # input directly \n",
    "label_logits = Input(shape=(max_len,), name='label_logits') # input directly\n",
    "\n",
    "total_loss = Lambda(custom_loss, name='ctc_loss')([label_seq, label_logits, out_seq, out_seq_trans])\n",
    "model = Model(inputs=[input_im,label_seq,label_logits], outputs=total_loss)\n",
    "\n",
    "\n",
    "# model = Model(inputs=[input_im,label_seq,label_logits], outputs=out_seq)\n",
    "\n",
    "adam = Adam()\n",
    "# model.add_loss(K.sum(total_loss, axis=None))\n",
    "\n",
    "model.compile(loss=lambda yt,yp: yp, \n",
    "              optimizer=adam) # the loss is whatever you get back from the model itself\n",
    "\n",
    "# loss is thus built into the model\n",
    "# Add loss to the metrics\n",
    "# model.metrics_names.append('pred')\n",
    "# model.metrics_tensors.append(model.layers[-2].output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRTensorBoard(TensorBoard):\n",
    "    def __init__(self, log_dir):  # add other arguments to __init__ if you need\n",
    "        super(LRTensorBoard, self).__init__(log_dir=log_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs.update({'lr': K.eval(self.model.optimizer.lr)})\n",
    "        super(LRTensorBoard, self).on_epoch_end(epoch, logs)\n",
    "\n",
    "class SaveToDrive(Callback):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def on_epoch_end(self, epoch):\n",
    "        for fname in os.listdir(model_name):\n",
    "            shutil.copy(os.path.join(model_name, fname), self.path)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_name+'/'+model_name+'.h5', \n",
    "                             monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "tensorboard = LRTensorBoard(log_dir='./'+model_name)\n",
    "# earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "cvslogger = CSVLogger(model_name+'/logs.csv', separator=',', append=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.000001, min_delta=0.03)\n",
    "save2drive = SaveToDrive(\"drive/Rabeez-Danish/RunSave\")\n",
    "\n",
    "# callbacks = [checkpoint, tensorboard, earlystop, cvslogger, reducelr]\n",
    "# callbacks = [checkpoint, tensorboard, cvslogger, reducelr, save2drive]\n",
    "callbacks = [checkpoint, tensorboard, cvslogger, reducelr]\n",
    "# callbacks = [checkpoint, cvslogger, reducelr]\n",
    "\n",
    "hist = model.fit_generator(train_gen, epochs=num_epochs, steps_per_epoch=len(train_set)//batch_size,  validation_data=val_gen, validation_steps=len(val_set)//batch_size, callbacks=callbacks, verbose=1)\n",
    "\n",
    "\n",
    "###################### FIX BEFORE, BEFORE WE CAN MOVE ON :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
